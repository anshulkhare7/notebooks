{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0638b-4a9a-4350-bc42-7d178b5c536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deca410-fce1-4e30-96eb-622f1b79e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 pdfplumber spacy nltk transformers torch\n",
    "!pip install os\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1d3cd31-aa7a-4091-89f3-108241df3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import PyPDF2\n",
    "import re\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from collections import Counter\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04b32e73-ba5d-4462-a8bd-21eb34a96045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pdf_to_text_pypdf2(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + '\\n'\n",
    "    return text\n",
    "\n",
    "def find_with_spacy_label(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"PRODUCT\"]]\n",
    "\n",
    "def find_submission_vicinity(text, limit=10):\n",
    "    lines = text.split('\\n')[:limit]\n",
    "    for line in lines:\n",
    "        if \"submission\" in line.lower():\n",
    "            potential_orgs = find_with_spacy_label(line)\n",
    "            if potential_orgs:\n",
    "                return potential_orgs[0]\n",
    "    return None\n",
    "\n",
    "def find_in_footer(text):\n",
    "    footer_pattern = r'(?:Â©|\\(c\\)|Copyright).*?([A-Z][a-z]+(?:[\\s&]+[A-Z][a-z]+)+)'\n",
    "    matches = re.findall(footer_pattern, text, re.IGNORECASE)\n",
    "    return matches\n",
    "\n",
    "def find_acronym(text):\n",
    "    lines = text.split('\\n')[:15]\n",
    "    acronym_pattern = r'\\b([A-Z]{2,})\\b'\n",
    "    acronyms = []\n",
    "    for line in lines:\n",
    "        matches = re.findall(acronym_pattern, line)\n",
    "        acronyms.extend(matches)\n",
    "    return acronyms\n",
    "\n",
    "def find_in_signature(text):\n",
    "    last_page = text.split('\\n')[-30:]  # Last 30 lines\n",
    "    signature_pattern = r'(?:Sincerely|Yours truly|Regards|Submitted by|On behalf of),?(?:\\s*\\n)*\\s*([A-Z][a-z]+(?:[\\s&]+[A-Z][a-z]+)+)'\n",
    "    matches = []\n",
    "    for i in range(len(last_page) - 1):\n",
    "        three_lines = ' '.join(last_page[i:i+3])\n",
    "        found_matches = re.findall(signature_pattern, three_lines, re.IGNORECASE)\n",
    "        matches.extend(found_matches)\n",
    "    return matches\n",
    "\n",
    "def find_participant(pdf_path):\n",
    "    text = pdf_to_text_pypdf2(pdf_path)\n",
    "    \n",
    "    potential_matches = []\n",
    "    \n",
    "    # Method 1: Organization with \"submission\" (high priority)\n",
    "    with_submission = find_submission_vicinity(text)\n",
    "    if with_submission:\n",
    "        potential_matches.append((with_submission, 3))\n",
    "    \n",
    "    # Method 2: Organization in footer\n",
    "    in_footer = find_in_footer(text)\n",
    "    potential_matches.extend((match, 2) for match in in_footer)\n",
    "    \n",
    "    # Method 3: Organization acronym\n",
    "    in_acronym = find_acronym(text)\n",
    "    potential_matches.extend((match, 1) for match in in_acronym)\n",
    "    \n",
    "    # Method 4: Organization in signature\n",
    "    in_signature = find_in_signature(text)\n",
    "    potential_matches.extend((match, 2) for match in in_signature)\n",
    "    \n",
    "    # Method 5: Using NER to find all potential organizations\n",
    "    with_spacy_label = find_with_spacy_label(text)\n",
    "    potential_matches.extend((match, 1) for match in with_spacy_label)\n",
    "\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Use a pre-trained model for organization entity recognition as a final check\n",
    "    ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\", device=device)\n",
    "    ner_results = ner_pipeline(text[:2000])  # First 2000 characters\n",
    "    ner_orgs = [result['word'] for result in ner_results if result['entity'] in ['B-ORG', 'I-ORG']]\n",
    "    potential_matches.extend((match, 1) for match in ner_orgs)\n",
    "    \n",
    "    # Count occurrences, considering priorities\n",
    "    match_counts = Counter()\n",
    "    for match, priority in potential_matches:\n",
    "        match_counts[match] += priority\n",
    "    \n",
    "    # Select the most likely participant\n",
    "    if match_counts:\n",
    "        most_common_match = max(match_counts.items(), key=lambda x: x[1])\n",
    "        return most_common_match[0] if most_common_match[1] > 1 else None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "312a227a-b345-47c1-8a8b-61c674e98941",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "files = {\n",
    "         \"tennox\" : os.getenv(\"tennox\"), \n",
    "         \"sayc\": os.getenv(\"sayc\"), \n",
    "         \"saru\" : os.getenv(\"saru\"), \n",
    "         \"uct\" : os.getenv(\"uct\"), \n",
    "         \"up\":  os.getenv(\"up\"), \n",
    "         \"bmi\" : os.getenv(\"bmi\")\n",
    "        }\n",
    "# print(file_path_tennox)\n",
    "# IFrame(file_path, width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77338671-ed7a-4bae-8ef2-6a81a8962f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tennox': 'Tenox Management Consultancy Inc', 'sayc': 'the SAYC by', 'saru': 'SARU', 'uct': 'SA', 'up': 'ICASA', 'bmi': 'SABC'}\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for key, value in files.items():\n",
    "    if value:  # Only call if value is not None\n",
    "        result[key] = find_participant(value)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a4e4e-a3ec-4587-b55c-f8764147e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nlp.get_pipe(\"ner\").labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
